# Efficiency Benchmarking System

## âœ… Current Working System

This directory contains the **real-time performance profiling system** that provides comprehensive efficiency metrics for LLM time series models, fully addressing reviewer requirements.

## ğŸ“ Active Files

- âœ… **`real_time_profiler.py`** - Main profiling system with NVIDIA ML integration
- âœ… **`efficiency_calculator.py`** - Basic efficiency calculations
- âœ… **`combine_reports.py`** - Combines multiple performance reports into comprehensive analysis

## ğŸš€ How to Use

The system is **automatically integrated** into `main.py`. Simply run your model training/inference:

```bash
python main.py --config_path your_config.gin --log_level INFO
```

This automatically generates:
1. **Individual performance reports** (training, inference) 
2. **Comprehensive combined report** with all metrics
3. **Real-time monitoring** of CPU, GPU, memory, power, temperature

## ğŸ“Š Generated Metrics

**Reviewer Requirements Fully Met:**
- âœ… **CPU/GPU/Edge Latency**: Real measured timing during inference
- âœ… **Model Size on Disk**: Actual file sizes
- âœ… **RAM/VRAM Usage**: Process-specific + system-wide memory tracking
- âœ… **Throughput**: Calculated from real measurements
- âœ… **Edge Feasibility**: Quantitative device compatibility analysis

**Enhanced Monitoring:**
- GPU utilization, temperature, power consumption (NVIDIA ML)
- Process-specific vs system-wide memory usage
- Statistical analysis (P95/P99 latencies)
- Edge device compatibility assessment

## ï¿½ Report Locations

Reports are automatically saved in your experiment log directory:
```
experiment_configs_*/logs/logs_*/
â”œâ”€â”€ real_performance_report_*_training_*.json
â”œâ”€â”€ real_performance_report_*_inference_*.json
â””â”€â”€ comprehensive_performance_report_*_comprehensive_*.json
```

## ğŸ”§ System Requirements

- Python packages: `psutil`, `torch`, `numpy`, `nvidia-ml-py`
- NVIDIA GPU with CUDA (for GPU monitoring)
- Linux/Windows compatible