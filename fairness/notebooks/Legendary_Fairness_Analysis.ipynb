{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac2160a",
   "metadata": {},
   "source": [
    "# ğŸ† LEGENDARY ALL-FEATURE FAIRNESS ANALYSIS ğŸ†\n",
    "\n",
    "## The Ultimate Fairness Analysis Notebook\n",
    "\n",
    "This notebook analyzes fairness across **ALL** demographic features in your OhioT1DM dataset:\n",
    "\n",
    "- ğŸ‘« **Gender**: Male vs Female\n",
    "- ğŸ‚ **Age Groups**: 20-40, 40-60, 60-80\n",
    "- ğŸ’‰ **Pump Models**: 630G, 530G\n",
    "- ğŸ“± **Sensor Brands**: Empatica, Basis\n",
    "- ğŸ“… **Study Cohorts**: 2020, 2018\n",
    "\n",
    "**This is the most comprehensive fairness analysis tool you'll ever need!** ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a06434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LEGENDARY analyzer\n",
    "import sys\n",
    "sys.path.append('../')  # Add parent directory to path\n",
    "from legendary_fairness_analyzer import LegendaryFairnessAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize the LEGENDARY analyzer\n",
    "analyzer = LegendaryFairnessAnalyzer()\n",
    "\n",
    "print(\"ğŸ† LEGENDARY ALL-FEATURE FAIRNESS ANALYZER LOADED!\")\n",
    "print(f\"ğŸš€ Analyzing {len(analyzer.patient_data)} patients across ALL demographic features\")\n",
    "print(\"ğŸ¯ This is the most comprehensive fairness analysis available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47243bc9",
   "metadata": {},
   "source": [
    "## ğŸ“Š Complete Demographic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba13d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show comprehensive demographics\n",
    "print(\"ğŸ“Š COMPREHENSIVE DEMOGRAPHIC OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Count by feature\n",
    "feature_counts = {\n",
    "    'Gender': {},\n",
    "    'Age': {},\n",
    "    'Pump Model': {},\n",
    "    'Sensor Band': {},\n",
    "    'Cohort': {}\n",
    "}\n",
    "\n",
    "for patient_data in analyzer.patient_data.values():\n",
    "    feature_counts['Gender'][patient_data['gender']] = feature_counts['Gender'].get(patient_data['gender'], 0) + 1\n",
    "    feature_counts['Age'][patient_data['age']] = feature_counts['Age'].get(patient_data['age'], 0) + 1\n",
    "    feature_counts['Pump Model'][patient_data['pump_model']] = feature_counts['Pump Model'].get(patient_data['pump_model'], 0) + 1\n",
    "    feature_counts['Sensor Band'][patient_data['sensor_band']] = feature_counts['Sensor Band'].get(patient_data['sensor_band'], 0) + 1\n",
    "    feature_counts['Cohort'][patient_data['cohort']] = feature_counts['Cohort'].get(patient_data['cohort'], 0) + 1\n",
    "\n",
    "total_patients = len(analyzer.patient_data)\n",
    "\n",
    "for feature_name, counts in feature_counts.items():\n",
    "    emoji = analyzer.feature_names.get(feature_name, 'ğŸ”')\n",
    "    print(f\"\\n{emoji} {feature_name}:\")\n",
    "    for value, count in counts.items():\n",
    "        percentage = (count / total_patients) * 100\n",
    "        print(f\"   {value}: {count} patients ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d658a3",
   "metadata": {},
   "source": [
    "## ğŸ¨ Demographic Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c705892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive demographic visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('ğŸ† LEGENDARY DEMOGRAPHIC OVERVIEW ğŸ†', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Color schemes for different features\n",
    "color_schemes = {\n",
    "    'Gender': ['#FF6B6B', '#4ECDC4'],\n",
    "    'Age': ['#FF6B6B', '#4ECDC4', '#45B7D1'], \n",
    "    'Pump Model': ['#96CEB4', '#FFEAA7'],\n",
    "    'Sensor Band': ['#DDA0DD', '#98FB98'],\n",
    "    'Cohort': ['#F0E68C', '#87CEEB']\n",
    "}\n",
    "\n",
    "# Plot each feature distribution\n",
    "plot_positions = [(0,0), (0,1), (0,2), (1,0), (1,1)]\n",
    "feature_names = ['Gender', 'Age', 'Pump Model', 'Sensor Band', 'Cohort']\n",
    "\n",
    "for idx, feature_name in enumerate(feature_names):\n",
    "    if idx >= len(plot_positions):\n",
    "        break\n",
    "        \n",
    "    row, col = plot_positions[idx]\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    counts = feature_counts[feature_name]\n",
    "    colors = color_schemes.get(feature_name, plt.cm.Set3(np.linspace(0, 1, len(counts))))\n",
    "    \n",
    "    ax.pie(counts.values(), labels=counts.keys(), autopct='%1.1f%%', colors=colors)\n",
    "    emoji = analyzer.feature_names.get(feature_name, 'ğŸ”')\n",
    "    ax.set_title(f'{emoji} {feature_name} Distribution', fontweight='bold')\n",
    "\n",
    "# Hide the last subplot\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67677e42",
   "metadata": {},
   "source": [
    "## ğŸ” THE LEGENDARY FAIRNESS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0427319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LEGENDARY analysis\n",
    "print(\"ğŸš€ INITIATING LEGENDARY FAIRNESS ANALYSIS...\")\n",
    "print(\"ğŸ¯ Analyzing fairness across ALL demographic features simultaneously!\")\n",
    "\n",
    "try:\n",
    "    all_results = analyzer.analyze_latest_experiment()\n",
    "    \n",
    "    if all_results:\n",
    "        print(\"\\nğŸ† LEGENDARY ANALYSIS COMPLETE!\")\n",
    "        print(f\"âœ… Successfully analyzed fairness across {len(all_results)} demographic features\")\n",
    "        \n",
    "        # Quick summary\n",
    "        fairness_levels = [result['fairness_level'] for result in all_results.values()]\n",
    "        excellent_count = sum(1 for level in fairness_levels if 'ğŸ†' in level)\n",
    "        good_count = sum(1 for level in fairness_levels if 'ğŸ‘' in level)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š FAIRNESS OVERVIEW:\")\n",
    "        print(f\"ğŸ† Excellent Features: {excellent_count}\")\n",
    "        print(f\"ğŸ‘ Good Features: {good_count}\")\n",
    "        print(f\"âš ï¸  Features Needing Attention: {len(all_results) - excellent_count - good_count}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"ğŸ’¥ Could not complete LEGENDARY analysis\")\n",
    "        print(\"Make sure you have run some distillation experiments first!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ğŸ’¥ Error during LEGENDARY analysis: {e}\")\n",
    "    print(\"Ensure you have experiment results in /workspace/LLM-TIME/distillation_experiments/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d81202",
   "metadata": {},
   "source": [
    "## ğŸ“Š Detailed Feature-by-Feature Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95184b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results for each feature\n",
    "if 'all_results' in locals() and all_results:\n",
    "    print(\"ğŸ“‹ DETAILED FEATURE-BY-FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for feature_key, result in all_results.items():\n",
    "        feature_name = result['feature_name']\n",
    "        emoji = analyzer.feature_names.get(feature_name, 'ğŸ”')\n",
    "        \n",
    "        print(f\"\\n{emoji} {feature_name.upper()} FAIRNESS:\")\n",
    "        print(f\"   âš–ï¸  MSE Fairness Ratio: {result['mse_ratio']:.3f}\")\n",
    "        print(f\"   ğŸ“Š MAE Fairness Ratio: {result['mae_ratio']:.3f}\")\n",
    "        print(f\"   ğŸ¯ Fairness Level: {result['fairness_level']}\")\n",
    "        print(f\"   ğŸ‘¥ Groups Analyzed: {len(result['feature_performance'])}\")\n",
    "        \n",
    "        # Show group breakdown\n",
    "        feature_perf = result['feature_performance']\n",
    "        print(f\"   ğŸ“ˆ Group Performance:\")\n",
    "        for group, perf in feature_perf.items():\n",
    "            print(f\"      {group}: {perf['count']} patients, MSE = {perf['mse']:.6f}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No detailed results available. Run the analysis above first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da67aee",
   "metadata": {},
   "source": [
    "## ğŸ¨ LEGENDARY VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ed3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LEGENDARY visualization\n",
    "if 'all_results' in locals() and all_results:\n",
    "    print(\"ğŸ¨ Creating LEGENDARY visualization...\")\n",
    "    analyzer.create_legendary_visualization(all_results)\n",
    "else:\n",
    "    print(\"âš ï¸  No results available for visualization\")\n",
    "    print(\"Run the LEGENDARY analysis section above first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d3ff0",
   "metadata": {},
   "source": [
    "## ğŸ† Champion Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and analyze the most and least fair features\n",
    "if 'all_results' in locals() and all_results:\n",
    "    print(\"ğŸ† CHAMPION FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Sort by fairness ratio\n",
    "    sorted_features = sorted(all_results.items(), key=lambda x: x[1]['mse_ratio'])\n",
    "    \n",
    "    # Most fair feature (champion)\n",
    "    champion = sorted_features[0]\n",
    "    champion_name = champion[1]['feature_name']\n",
    "    champion_ratio = champion[1]['mse_ratio']\n",
    "    champion_emoji = analyzer.feature_names.get(champion_name, 'ğŸ”')\n",
    "    \n",
    "    print(f\"ğŸ¥‡ FAIRNESS CHAMPION: {champion_emoji} {champion_name}\")\n",
    "    print(f\"   Fairness Ratio: {champion_ratio:.3f}\")\n",
    "    print(f\"   Level: {champion[1]['fairness_level']}\")\n",
    "    print(f\"   ğŸ¯ This feature shows the best fairness in your model!\")\n",
    "    \n",
    "    # Least fair feature (needs attention)\n",
    "    challenger = sorted_features[-1]\n",
    "    challenger_name = challenger[1]['feature_name']\n",
    "    challenger_ratio = challenger[1]['mse_ratio']\n",
    "    challenger_emoji = analyzer.feature_names.get(challenger_name, 'ğŸ”')\n",
    "    \n",
    "    print(f\"\\nâš ï¸  NEEDS ATTENTION: {challenger_emoji} {challenger_name}\")\n",
    "    print(f\"   Fairness Ratio: {challenger_ratio:.3f}\")\n",
    "    print(f\"   Level: {challenger[1]['fairness_level']}\")\n",
    "    print(f\"   ğŸ”§ This feature has the most room for fairness improvement\")\n",
    "    \n",
    "    # Calculate improvement potential\n",
    "    improvement_potential = challenger_ratio / champion_ratio\n",
    "    print(f\"\\nğŸ“Š IMPROVEMENT POTENTIAL: {improvement_potential:.2f}x\")\n",
    "    \n",
    "    if improvement_potential > 2.0:\n",
    "        print(f\"ğŸš€ MAJOR OPPORTUNITY: Significant fairness gains possible!\")\n",
    "    elif improvement_potential > 1.5:\n",
    "        print(f\"ğŸ’¡ GOOD OPPORTUNITY: Moderate fairness improvements available\")\n",
    "    else:\n",
    "        print(f\"âœ… WELL BALANCED: All features show similar fairness levels\")\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸  No champion analysis available. Run the main analysis first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2e5a9",
   "metadata": {},
   "source": [
    "## ğŸ¯ LEGENDARY RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide comprehensive recommendations\n",
    "if 'all_results' in locals() and all_results:\n",
    "    print(\"ğŸ¯ LEGENDARY FAIRNESS RECOMMENDATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Count fairness levels\n",
    "    fairness_counts = {}\n",
    "    poor_features = []\n",
    "    excellent_features = []\n",
    "    \n",
    "    for feature_key, result in all_results.items():\n",
    "        level = result['fairness_level']\n",
    "        fairness_counts[level] = fairness_counts.get(level, 0) + 1\n",
    "        \n",
    "        if 'ğŸ’¥' in level:  # Poor\n",
    "            poor_features.append(result['feature_name'])\n",
    "        elif 'ğŸ†' in level:  # Excellent\n",
    "            excellent_features.append(result['feature_name'])\n",
    "    \n",
    "    print(f\"ğŸ“Š OVERALL FAIRNESS HEALTH:\")\n",
    "    total_features = len(all_results)\n",
    "    excellent_pct = (fairness_counts.get('ğŸ† Excellent', 0) / total_features) * 100\n",
    "    \n",
    "    if excellent_pct >= 80:\n",
    "        print(f\"ğŸ† LEGENDARY STATUS: {excellent_pct:.0f}% of features show excellent fairness!\")\n",
    "        print(f\"âœ… Your model demonstrates exceptional fairness across demographics\")\n",
    "    elif excellent_pct >= 60:\n",
    "        print(f\"ğŸ‘ GOOD STATUS: {excellent_pct:.0f}% of features show excellent fairness\")\n",
    "        print(f\"ğŸ’¡ Minor improvements could push you to legendary status\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  IMPROVEMENT NEEDED: Only {excellent_pct:.0f}% of features show excellent fairness\")\n",
    "        print(f\"ğŸ”§ Significant fairness work recommended\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ PRIORITY ACTIONS:\")\n",
    "    \n",
    "    if poor_features:\n",
    "        print(f\"ğŸ”¥ IMMEDIATE ATTENTION: {', '.join(poor_features)}\")\n",
    "        print(f\"   â€¢ Implement fairness constraints for these features\")\n",
    "        print(f\"   â€¢ Collect more balanced training data\")\n",
    "        print(f\"   â€¢ Consider feature-specific model adaptations\")\n",
    "    \n",
    "    if excellent_features:\n",
    "        print(f\"\\nğŸ† MAINTAIN EXCELLENCE: {', '.join(excellent_features)}\")\n",
    "        print(f\"   â€¢ Continue current practices for these features\")\n",
    "        print(f\"   â€¢ Use as benchmarks for other features\")\n",
    "        print(f\"   â€¢ Monitor in future experiments\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ NEXT STEPS:\")\n",
    "    print(f\"1. ğŸ“š Review the Fairness_Integration_Guide.ipynb for training improvements\")\n",
    "    print(f\"2. ğŸ¯ Focus on the {len(poor_features) + fairness_counts.get('âš ï¸  Acceptable', 0)} features needing improvement\")\n",
    "    print(f\"3. ğŸ“Š Re-run this analysis after implementing changes\")\n",
    "    print(f\"4. ğŸ† Aim for 100% excellent fairness across all features!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  No recommendations available. Run the main analysis first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd5978",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save LEGENDARY Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LEGENDARY results\n",
    "if 'all_results' in locals() and all_results:\n",
    "    analyzer.save_legendary_results(all_results, \"legendary_fairness_analysis_results.json\")\n",
    "    \n",
    "    print(\"ğŸ“Š Additional files saved:\")\n",
    "    print(\"   â€¢ legendary_fairness_analysis_results.json - Complete analysis results\")\n",
    "    print(\"   â€¢ Contains fairness metrics for all demographic features\")\n",
    "    print(\"   â€¢ Use for further analysis or reporting\")\n",
    "    \n",
    "    # Create summary DataFrame for easy viewing\n",
    "    summary_data = []\n",
    "    for feature_key, result in all_results.items():\n",
    "        summary_data.append({\n",
    "            'Feature': result['feature_name'],\n",
    "            'MSE_Ratio': result['mse_ratio'],\n",
    "            'MAE_Ratio': result['mae_ratio'],\n",
    "            'Fairness_Level': result['fairness_level'],\n",
    "            'Groups': len(result['feature_performance'])\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('MSE_Ratio')\n",
    "    \n",
    "    print(\"\\nğŸ“‹ FAIRNESS SUMMARY TABLE:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Save summary CSV\n",
    "    summary_df.to_csv('legendary_fairness_summary.csv', index=False)\n",
    "    print(\"\\nğŸ’¾ Summary table saved to: legendary_fairness_summary.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  No results to save. Run the LEGENDARY analysis first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28643c95",
   "metadata": {},
   "source": [
    "## ğŸ† LEGENDARY STATUS ACHIEVEMENT\n",
    "\n",
    "Congratulations! You've completed the most comprehensive fairness analysis available. \n",
    "\n",
    "### ğŸ¯ What You've Accomplished:\n",
    "- âœ… Analyzed fairness across **ALL** demographic features\n",
    "- ğŸ“Š Generated comprehensive visualizations and metrics  \n",
    "- ğŸ† Identified your fairness champions and improvement opportunities\n",
    "- ğŸ’¡ Received personalized recommendations for each feature\n",
    "- ğŸ’¾ Saved detailed results for future reference\n",
    "\n",
    "### ğŸš€ Your Fairness Journey:\n",
    "1. **Current Analysis** â† You are here\n",
    "2. **Implement Improvements** (use `Fairness_Integration_Guide.ipynb`)\n",
    "3. **Re-analyze & Validate** (run this notebook again)\n",
    "4. **Achieve Legendary Fairness** (100% excellent across all features)\n",
    "\n",
    "### ğŸ‰ Share Your Success:\n",
    "Your comprehensive fairness analysis demonstrates commitment to ethical AI and inclusive healthcare technology. This level of analysis puts you at the forefront of responsible machine learning!\n",
    "\n",
    "**Keep pushing the boundaries of fair and inclusive AI! ğŸŒŸ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
