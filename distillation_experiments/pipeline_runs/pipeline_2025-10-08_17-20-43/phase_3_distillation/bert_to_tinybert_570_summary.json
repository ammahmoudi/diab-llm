{
  "teacher_model": "bert",
  "student_model": "tinybert",
  "dataset": "570",
  "config_path": "distillation_experiments/pipeline_runs/pipeline_2025-10-08_17-20-43/configs/config_distill_bert_to_tinybert_570.gin",
  "teacher_checkpoint": "distillation_experiments/pipeline_runs/pipeline_2025-10-08_17-20-43/phase_1_teacher/bert_570_1epochs/logs/logs_2025-10-08_17-20-50/checkpoints/checkpoint.pth",
  "student_config": {
    "llm_model": "TinyBERT",
    "llm_layers": 4,
    "llm_dim": 312,
    "model_comment": "student_TinyBERT_312_6_6_9_6"
  },
  "distillation_params": {
    "alpha": 0.5,
    "beta": 0.5,
    "kl_weight": 0.1,
    "temperature": 3.0,
    "train_epochs": 1,
    "learning_rate": 0.0005
  },
  "status": "completed"
}