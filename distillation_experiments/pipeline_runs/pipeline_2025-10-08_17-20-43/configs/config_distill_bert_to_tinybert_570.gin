run.log_dir = "distillation_experiments/pipeline_runs/pipeline_2025-10-08_17-20-43/phase_3_distillation/bert_to_tinybert_570/logs"
run.data_settings = {
    'path_to_train_data': './data/ohiot1dm/raw_standardized/570-ws-training.csv',
    'path_to_test_data': './data/ohiot1dm/raw_standardized/570-ws-testing.csv',
    'input_features': ['target'],
    'labels': ['target'],
    'prompt_path': './data/ohiot1dm/raw_standardized/t1dm_prompt.txt',
    'preprocessing_method': 'min_max',
    'preprocess_input_features': False,
    'preprocess_label': False,
    'frequency': '5min',
    'percent': 100,
    'val_split': 0,
}

run.llm_settings = {
    'task_name': 'long_term_forecast',
    'mode': 'training+inference',
    'method': 'distillation',
    'num_workers': 1,
    'torch_dtype': 'float32',
    'model_id': 'distilled_student',
    'sequence_length': 6,
    'context_length': 6,
    'prediction_length': 9,
    'patch_len': 6,
    'stride': 8,
    'prediction_batch_size': 64,
    'train_batch_size': 32,
    'features': 'S',
    'd_model': 32,
    'd_ff': 32,
    'factor': 1,
    'enc_in': 1,
    'dec_in': 1,
    'c_out': 1,
    'e_layers': 2,
    'd_layers': 1,
    'n_heads': 8,
    'dropout': 0.1,
    'moving_avg': 25,
    'activation': 'gelu',
    'embed': 'timeF',
    'patience': 10,
    'lradj': 'COS',
    'des': 'distillation',
    'prompt_domain': 0,
    'timeenc': 0,
    'eval_metrics': ['rmse', 'mae', 'mape'],
    'seed': 238822,
    'restore_from_checkpoint': False,
    'train_epochs': 1,
    'teacher_checkpoint_path': 'distillation_experiments/pipeline_runs/pipeline_2025-10-08_17-20-43/phase_1_teacher/bert_570_1epochs/logs/logs_2025-10-08_17-20-50/checkpoints/checkpoint.pth',
    'llm_model': 'TinyBERT',
    'llm_layers': 4,
    'llm_dim': 312,
    'model_comment': 'student_TinyBERT_312_6_6_9_6',
    'alpha': 0.5,
    'beta': 0.5,
    'kl_weight': 0.1,
    'temperature': 3.0,
    'learning_rate': 0.0005,
    'teacher_model': 'BERT',
}
