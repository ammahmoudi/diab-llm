run.log_dir = "./distillation_experiments/ohiot1dm_distillation/seed_238822_model_TinyBERT_dim_312_seq_6_context_6_pred_9_patch_6_epochs_1/patient_570/logs"

run.data_settings = {
    'input_features': ['target'],
    'labels': ['target'],
    'preprocessing_method': 'min_max',
    'preprocess_input_features': False,
    'preprocess_label': False,
    'frequency': '5min',
    'percent': 100,
    'val_split': 0,
    'path_to_train_data': '/home/amma/LLM-TIME/data/ohiot1dm/raw_standardized/570-ws-training.csv',
    'path_to_test_data': '/home/amma/LLM-TIME/data/ohiot1dm/raw_standardized/570-ws-testing.csv',
    'prompt_path': '/home/amma/LLM-TIME/data/ohiot1dm/raw_standardized/t1dm_prompt.txt',
}

run.llm_settings = {
    'task_name': 'long_term_forecast',
    'mode': 'training+inference',
    'num_workers': 1,
    'torch_dtype': 'float32',
    'model_id': 'experiment',
    'sequence_length': 6,
    'context_length': 6,
    'prediction_length': 9,
    'patch_len': 6,
    'stride': 8,
    'prediction_batch_size': 64,
    'train_batch_size': 32,
    'learning_rate': 0.001,
    'train_epochs': 1,
    'features': 'S',
    'd_model': 32,
    'd_ff': 32,
    'factor': 1,
    'enc_in': 1,
    'dec_in': 1,
    'c_out': 1,
    'e_layers': 2,
    'd_layers': 1,
    'n_heads': 8,
    'dropout': 0.1,
    'moving_avg': 25,
    'activation': 'gelu',
    'embed': 'timeF',
    'patience': 10,
    'lradj': 'COS',
    'des': 'experiment',
    'prompt_domain': 0,
    'timeenc': 0,
    'eval_metrics': ['rmse', 'mae', 'mape'],
    'seed': 238822,
    'llm_model': 'TinyBERT',
    'llm_layers': 4,
    'llm_dim': 312,
    'method': 'time_llm',
    'type': 'teacher',
    'model_comment': 'TinyBERT_ohiot1dm_raw_standardized_570_1epochs',
}
