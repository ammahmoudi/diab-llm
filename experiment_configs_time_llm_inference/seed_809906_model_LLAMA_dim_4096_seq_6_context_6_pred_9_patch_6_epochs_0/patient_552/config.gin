run.log_dir = "./experiment_configs_time_llm_inference/seed_809906_model_LLAMA_dim_4096_seq_6_context_6_pred_9_patch_6_epochs_0/patient_552/logs"
run.data_settings = {
    'path_to_train_data': './data/standardized/552-ws-training.csv',
    'path_to_test_data': './data/standardized/552-ws-testing.csv',
    'input_features': ['target'],
    'labels': ['target'],
    'prompt_path': './data/standardized/t1dm_prompt.txt',
    'preprocessing_method': 'min_max',
    'preprocess_input_features': False,
    'preprocess_label': False,
    'frequency': '5min',
    'percent': 100,
    'val_split': 0
}

run.llm_settings = {
    'task_name': 'long_term_forecast',
    'mode': 'training+inference',
    'method': 'time_llm',
    'llm_model': 'LLAMA',
    'llm_layers': 32,
    'llm_dim': 4096,
    'num_workers': 1,
    'torch_dtype': 'bfloat16',
    'model_id': 'test',
    'sequence_length': 6,
    'context_length': 6,
    'prediction_length': 9,
    'patch_len': 6,
    'stride': 8,
    'prediction_batch_size': 64,
    'train_batch_size': 2,
    'learning_rate': 0.001,
    'train_epochs': 0,
    'features': 'S',
    'd_model': 32,
    'd_ff': 32,
    'factor': 1,
    'enc_in': 1,
    'dec_in': 1,
    'c_out': 1,
    'e_layers': 2,
    'd_layers': 1,
    'n_heads': 8,
    'dropout': 0.1,
    'moving_avg': 25,
    'activation': 'gelu',
    'embed': 'timeF',
    'patience': 10,
    'lradj': 'COS',
    'des': 'test',
    'model_comment': 'time_llm_LLAMA_4096_6_6_9_6',
    'prompt_domain': 0,
    'timeenc': 0,
    'eval_metrics': ['rmse', 'mae', 'mape'],
    'seed': 809906
}