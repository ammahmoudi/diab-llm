{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path to the project directory using the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "project_path = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the project path to sys.path if it's not already present\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from utils.result_saver import generate_latex_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeLLM Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/experiment_configs_time_llm_inference/experiment_results_time_llm_inference.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m time_llm_inference_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/experiment_configs_time_llm_inference/experiment_results_time_llm_inference.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df_time_llm_inference \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_llm_inference_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m latex_time_llm_inference\u001b[38;5;241m=\u001b[39mgenerate_latex_tables(\n\u001b[1;32m      4\u001b[0m     df_time_llm_inference,\n\u001b[1;32m      5\u001b[0m     title_template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero-shot Performance for Time-LLM Models (\u001b[39m\u001b[38;5;132;01m{time_horizon}\u001b[39;00m\u001b[38;5;124m-minute Forecast)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/LLM-TIME/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM-TIME/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/LLM-TIME/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM-TIME/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/LLM-TIME/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/experiment_configs_time_llm_inference/experiment_results_time_llm_inference.csv'"
     ]
    }
   ],
   "source": [
    "time_llm_inference_path = \"../results/experiment_configs_time_llm_inference/experiment_results_time_llm_inference.csv\"\n",
    "df_time_llm_inference = pd.read_csv(time_llm_inference_path)\n",
    "latex_time_llm_inference=generate_latex_tables(\n",
    "    df_time_llm_inference,\n",
    "    title_template=\"Zero-shot Performance for Time-LLM Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:timellm_zero_shot_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeLLM Fine-tunned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae70ac0>\n"
     ]
    }
   ],
   "source": [
    "time_llm_training_path = \"../results/experiment_configs_time_llm_training/experiment_results_time_llm_training.csv\"\n",
    "df_time_llm_training = pd.read_csv(time_llm_training_path)\n",
    "latex_time_llm_training=generate_latex_tables(\n",
    "    df_time_llm_training,\n",
    "    title_template=\"Fine-tunned Performance for Time-LLM Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:timellm_fine_tunned_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronos Zero-shot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae75a00>\n"
     ]
    }
   ],
   "source": [
    "chronos_inference_path = \"../results/experiment_configs_chronos_inference/experiment_results_chronos_inference_fixed.csv\"\n",
    "df_chronos_inference = pd.read_csv(chronos_inference_path)\n",
    "latex_chronos_inference=generate_latex_tables(\n",
    "    df_chronos_inference,\n",
    "    title_template=\"Zero-shot Performance for Chronos Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:chronos_zero_shot_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronos Fine-tunned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae80940>\n"
     ]
    }
   ],
   "source": [
    "chronos_training_path = \"../results/experiment_configs_chronos_training_inference/experiment_results_chronos_training_inference_fixed.csv\"\n",
    "df_chronos_training = pd.read_csv(chronos_training_path)\n",
    "latex_chronos_training=generate_latex_tables(\n",
    "    df_chronos_training,\n",
    "    title_template=\"Fine-tunned Performance for Chronos Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:chronos_fine_tunned_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae82b40>\n"
     ]
    }
   ],
   "source": [
    "chronos_training_lora_path = \"../results/experiment_configs_chronos_training_inference_lora/experiment_results_chronos_training_inference_lora_fixed.csv\"\n",
    "df_chronos_training_lora = pd.read_csv(chronos_training_lora_path)\n",
    "latex_chronos_training_lora=generate_latex_tables(\n",
    "    df_chronos_training_lora,\n",
    "    title_template=\"LoRA Fine-tunned Performance for Chronos Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:chronos_lora_fine_tunned_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h]\n",
      "    \\centering\n",
      "    \\caption{Model Performance Comparison (Seq 6, Pred 9)}\n",
      "    \\begin{tabular}{lcc}\n",
      "        \\toprule\n",
      "        \\textbf{Model} & \\textbf{RMSE} & \\textbf{MAE} \\\\\n",
      "        \\midrule\n",
      "        TimeLLM (Fine-tuned) (BERT) & 21.59 & 13.49 \\\\\n",
      "        TimeLLM (Fine-tuned) (LLAMA 7B (8 layers)) & 21.27 & 13.52 \\\\\n",
      "        TimeLLM (Fine-tuned) (LLAMA 7B (16 layers)) & 21.40 & 13.60 \\\\\n",
      "        TimeLLM (Fine-tuned) (GPT2) & 21.47 & 13.62 \\\\\n",
      "        Chronos (Fine-tuned) (amazon-chronos-t5-base) & 27.22 & 17.26 \\\\\n",
      "        Chronos (Zero-shot) (amazon-chronos-t5-base) & 28.79 & 18.38 \\\\\n",
      "        Chronos (Fine-tuned) (amazon-chronos-t5-tiny) & 29.14 & 19.05 \\\\\n",
      "        TimeLLM (Zero-shot) (GPT2) & 28.23 & 19.75 \\\\\n",
      "        Chronos (Zero-shot) (amazon-chronos-t5-tiny) & 29.90 & 19.77 \\\\\n",
      "        TimeLLM (Zero-shot) (BERT) & 28.45 & 19.84 \\\\\n",
      "        TimeLLM (Zero-shot) (LLAMA 7B (8 layers)) & 28.74 & 19.97 \\\\\n",
      "        TimeLLM (Zero-shot) (LLAMA 7B (16 layers)) & 29.45 & 20.31 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\label{tab:models_performance_comparison}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of models and their corresponding DataFrames\n",
    "from utils.result_saver import generate_model_comparison_from_dict\n",
    "\n",
    "\n",
    "model_dfs = {\n",
    "    # \"LSTM+WaveNet+GRU \\\\cite{DUDUKCU20211208}\": df1,\n",
    "    # \"Deep RL \\\\cite{DOMANSKI2024481}\": df2,\n",
    "    \"TimeLLM (Zero-shot)\": df_time_llm_inference,\n",
    "    \"TimeLLM (Fine-tuned)\": df_time_llm_training,\n",
    "    \"Chronos (Zero-shot)\": df_chronos_inference,\n",
    "    \"Chronos (Fine-tuned)\": df_chronos_training\n",
    "}\n",
    "\n",
    "# Generate model comparison table for seq=6, pred=9\n",
    "comparison_df, latex_code = generate_model_comparison_from_dict(model_dfs, seq=6, pred=9, save=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# import ace_tools as tools\n",
    "# tools.display_dataframe_to_user(name=\"Model Comparison Table\", dataframe=comparison_df)\n",
    "\n",
    "# Print LaTeX code (optional)\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\\\begin{table}[h]\\n    \\\\centering\\n    \\\\caption{Cross-Patient Model Performance}\\n    \\\\begin{tabular}{lcc|cc}\\n        \\\\toprule\\n        \\\\textbf{Model} & \\\\textbf{Train ID} & \\\\textbf{Test ID} & \\\\textbf{RMSE} & \\\\textbf{MAE} \\\\\\\\\\n        \\\\midrule\\n        GPT2 & 570 & 570 & 16.81 & 11.01 \\\\\\\\\\n         & 570 & 584 & 26.63 & 15.40 \\\\\\\\\\n         & 584 & 570 & 17.63 & 11.76 \\\\\\\\\\n         & 584 & 584 & 27.23 & 16.06 \\\\\\\\\\n        amazon-chronos-t5-base & 570 & 570 & 23.69 & 15.48 \\\\\\\\\\n         & 570 & 584 & 31.68 & 19.59 \\\\\\\\\\n         & 584 & 570 & 22.09 & 14.26 \\\\\\\\\\n         & 584 & 584 & 30.76 & 18.70 \\\\\\\\\\n        \\\\bottomrule\\n    \\\\end{tabular}\\n    \\\\label{tab:cross_patient_performance}\\n\\\\end{table}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.latex_tools import generate_cross_patient_latex_table_from_df\n",
    "\n",
    "cross_patient_df=pd.read_csv('../results/experiment_configs_crosspatient/experiment_results_crosspatient.csv')\n",
    "generate_cross_patient_latex_table_from_df(cross_patient_df,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing and Noise Analysysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_info_from_filename(filename: str):\n",
    "    if \"missing_periodic\" in filename:\n",
    "        corruption = \"missing_periodic\"\n",
    "    elif \"missing_random\" in filename:\n",
    "        corruption = \"missing_random\"\n",
    "    elif \"noisy\" in filename:\n",
    "        corruption = \"noisy\"\n",
    "    else:\n",
    "        corruption = \"unknown\"\n",
    "\n",
    "    if re.search(r\"training_(missing|noisy)\", filename):\n",
    "        scenario = \"fine-tuned\"\n",
    "    else:\n",
    "        scenario = \"zero-shot\"\n",
    "\n",
    "    return corruption, scenario\n",
    "\n",
    "def load_fixed_csvs(folder: str):\n",
    "    files = glob(os.path.join(folder, \"*fixed.csv\"))\n",
    "    all_data = []\n",
    "\n",
    "    for file_path in files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        corruption, scenario = extract_info_from_filename(filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"corruption_type\"] = corruption\n",
    "        df[\"scenario\"] = scenario\n",
    "\n",
    "        all_data.append(df)\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all fixed config CSVs\n",
    "df_all = load_fixed_csvs(\"../results/experiment_configs_chronos_missing_and_noisy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[htbp]\n",
      "\\centering\n",
      "\\caption{Chronos base model performance under test-time missingness and noise-aware evaluation across simulated corruption patterns. Metrics reported: Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).}\n",
      "\\label{tab:chronos_base_robustness}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lcc|cc}\n",
      "\\toprule\n",
      "\\textbf{Scenario} & \\multicolumn{2}{c}{\\textbf{Patient 570}} & \\multicolumn{2}{c}{\\textbf{Patient 584}} \\\\\n",
      " & MAE & RMSE & MAE & RMSE \\\\\n",
      "\\cmidrule(lr){2-5}\n",
      "Noisy — Noise-aware evaluation & 19.61 ± 0.14 & 28.38 ± 0.50 & 21.00 ± 0.26 & 32.55 ± 0.53 \\\\\n",
      "Noisy — Test-time missingness & 16.71 ± 0.17 & 24.40 ± 0.31 & 20.49 ± 0.23 & 34.09 ± 4.95 \\\\\n",
      "\\midrule\n",
      "Periodic missing — Noise-aware evaluation & 34.31 ± 0.19 & 70.28 ± 0.25 & 32.42 ± 0.18 & 60.61 ± 0.22 \\\\\n",
      "Periodic missing — Test-time missingness & 29.71 ± 0.30 & 64.68 ± 0.56 & 30.10 ± 0.68 & 58.97 ± 2.25 \\\\\n",
      "\\midrule\n",
      "Random missing — Noise-aware evaluation & 37.06 ± 0.72 & 73.38 ± 1.14 & 31.09 ± 0.24 & 57.74 ± 0.34 \\\\\n",
      "Random missing — Test-time missingness & 27.77 ± 0.26 & 59.24 ± 0.44 & 28.96 ± 0.44 & 55.11 ± 1.88 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "from utils.result_saver import generate_latex_chronos_robustness_table, prepare_chronos_robustness_table\n",
    "\n",
    "\n",
    "comparison_df = prepare_chronos_robustness_table(df_all, model_filter=\"amazon-chronos-t5-base\")\n",
    "\n",
    "latex_code = generate_latex_chronos_robustness_table(\n",
    "    comparison_df,\n",
    "    caption=\"Chronos base model performance under test-time missingness and noise-aware evaluation across simulated corruption patterns. Metrics reported: Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\",\n",
    "    label=\"tab:chronos_base_robustness\"\n",
    ")\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_time_llm_results(folder=\".\"):\n",
    "    files = glob(os.path.join(folder, \"experiment_configs_time_llm_training_*.csv\"))\n",
    "    data_frames = []\n",
    "\n",
    "    for file_path in files:\n",
    "        filename = os.path.basename(file_path)\n",
    "\n",
    "        # Determine corruption type\n",
    "        if \"missing_periodic\" in filename:\n",
    "            corruption = \"missing_periodic\"\n",
    "        elif \"missing_random\" in filename:\n",
    "            corruption = \"missing_random\"\n",
    "        elif \"noisy\" in filename:\n",
    "            corruption = \"noisy\"\n",
    "        else:\n",
    "            continue  # skip unknown\n",
    "\n",
    "        # Determine training config based on \"_train.csv\"\n",
    "        if filename.endswith(\"_train.csv\"):\n",
    "            scenario = \"fine-tuned\"  # noise-aware\n",
    "        else:\n",
    "            scenario = \"zero-shot\"  # standard training\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"corruption_type\"] = corruption\n",
    "        df[\"scenario\"] = scenario\n",
    "        data_frames.append(df)\n",
    "\n",
    "    return pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[htbp]\n",
      "\\centering\n",
      "\\caption{Time-LLM performance under test-time missingness and noise-aware evaluation across synthetic corruption patterns. Metrics reported: MAE and RMSE.}\n",
      "\\label{tab:time_llm_robustness}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lcc|cc}\n",
      "\\toprule\n",
      "\\textbf{Scenario} & \\multicolumn{2}{c}{\\textbf{Patient 570}} & \\multicolumn{2}{c}{\\textbf{Patient 584}} \\\\\n",
      " & MAE & RMSE & MAE & RMSE \\\\\n",
      "\\cmidrule(lr){2-5}\n",
      "Noisy — Noise-aware evaluation & 12.12 ± 0.07 & 17.73 ± 0.07 & 16.37 ± 0.36 & 27.12 ± 0.47 \\\\\n",
      "Noisy — Test-time missingness & 12.33 ± 0.08 & 17.93 ± 0.14 & 16.29 ± 0.12 & 26.97 ± 0.21 \\\\\n",
      "\\midrule\n",
      "Periodic missing — Noise-aware evaluation & 23.70 ± 0.35 & 51.77 ± 0.24 & 25.71 ± 0.03 & 48.98 ± 0.20 \\\\\n",
      "Periodic missing — Test-time missingness & 27.82 ± 0.69 & 66.77 ± 0.59 & 27.68 ± 0.59 & 58.12 ± 0.89 \\\\\n",
      "\\midrule\n",
      "Random missing — Noise-aware evaluation & 26.78 ± 0.84 & 55.07 ± 0.44 & 27.80 ± 0.09 & 50.20 ± 0.06 \\\\\n",
      "Random missing — Test-time missingness & 43.82 ± 3.23 & 84.61 ± 7.86 & 40.32 ± 2.62 & 72.39 ± 5.07 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "df_time_llm = load_time_llm_results(\"../results/experiment_configs_timellm_missing_and_noisy\")\n",
    "\n",
    "comparison_df_llm = prepare_chronos_robustness_table(df_time_llm, model_filter=\"LLAMA\")\n",
    "\n",
    "latex_llm = generate_latex_chronos_robustness_table(\n",
    "    comparison_df_llm,\n",
    "    caption=\"Time-LLM performance under test-time missingness and noise-aware evaluation across synthetic corruption patterns. Metrics reported: MAE and RMSE.\",\n",
    "    label=\"tab:time_llm_robustness\"\n",
    ")\n",
    "\n",
    "print(latex_llm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
