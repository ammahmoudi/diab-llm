{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path to the project directory using the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "project_path = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the project path to sys.path if it's not already present\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.result_saver import generate_latex_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeLLM Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae5ea80>\n"
     ]
    }
   ],
   "source": [
    "time_llm_inference_path = \"../results/experiment_configs_time_llm_inference/experiment_results_time_llm_inference.csv\"\n",
    "df_time_llm_inference = pd.read_csv(time_llm_inference_path)\n",
    "latex_time_llm_inference=generate_latex_tables(\n",
    "    df_time_llm_inference,\n",
    "    title_template=\"Zero-shot Performance for Time-LLM Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:timellm_zero_shot_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeLLM Fine-tunned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae70ac0>\n"
     ]
    }
   ],
   "source": [
    "time_llm_training_path = \"../results/experiment_configs_time_llm_training/experiment_results_time_llm_training.csv\"\n",
    "df_time_llm_training = pd.read_csv(time_llm_training_path)\n",
    "latex_time_llm_training=generate_latex_tables(\n",
    "    df_time_llm_training,\n",
    "    title_template=\"Fine-tunned Performance for Time-LLM Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:timellm_fine_tunned_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronos Zero-shot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae75a00>\n"
     ]
    }
   ],
   "source": [
    "chronos_inference_path = \"../results/experiment_configs_chronos_inference/experiment_results_chronos_inference_fixed.csv\"\n",
    "df_chronos_inference = pd.read_csv(chronos_inference_path)\n",
    "latex_chronos_inference=generate_latex_tables(\n",
    "    df_chronos_inference,\n",
    "    title_template=\"Zero-shot Performance for Chronos Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:chronos_zero_shot_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronos Fine-tunned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae80940>\n"
     ]
    }
   ],
   "source": [
    "chronos_training_path = \"../results/experiment_configs_chronos_training_inference/experiment_results_chronos_training_inference_fixed.csv\"\n",
    "df_chronos_training = pd.read_csv(chronos_training_path)\n",
    "latex_chronos_training=generate_latex_tables(\n",
    "    df_chronos_training,\n",
    "    title_template=\"Fine-tunned Performance for Chronos Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:chronos_fine_tunned_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7fc98ae82b40>\n"
     ]
    }
   ],
   "source": [
    "chronos_training_lora_path = \"../results/experiment_configs_chronos_training_inference_lora/experiment_results_chronos_training_inference_lora_fixed.csv\"\n",
    "df_chronos_training_lora = pd.read_csv(chronos_training_lora_path)\n",
    "latex_chronos_training_lora=generate_latex_tables(\n",
    "    df_chronos_training_lora,\n",
    "    title_template=\"LoRA Fine-tunned Performance for Chronos Models ({time_horizon}-minute Forecast)\",\n",
    "    label_template=\"tab:chronos_lora_fine_tunned_{time_horizon}min\",\n",
    "    freq=5,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h]\n",
      "    \\centering\n",
      "    \\caption{Model Performance Comparison (Seq 6, Pred 9)}\n",
      "    \\begin{tabular}{lcc}\n",
      "        \\toprule\n",
      "        \\textbf{Model} & \\textbf{RMSE} & \\textbf{MAE} \\\\\n",
      "        \\midrule\n",
      "        TimeLLM (Fine-tuned) (BERT) & 21.59 & 13.49 \\\\\n",
      "        TimeLLM (Fine-tuned) (LLAMA 7B (8 layers)) & 21.27 & 13.52 \\\\\n",
      "        TimeLLM (Fine-tuned) (LLAMA 7B (16 layers)) & 21.40 & 13.60 \\\\\n",
      "        TimeLLM (Fine-tuned) (GPT2) & 21.47 & 13.62 \\\\\n",
      "        Chronos (Fine-tuned) (amazon-chronos-t5-base) & 27.22 & 17.26 \\\\\n",
      "        Chronos (Zero-shot) (amazon-chronos-t5-base) & 28.79 & 18.38 \\\\\n",
      "        Chronos (Fine-tuned) (amazon-chronos-t5-tiny) & 29.14 & 19.05 \\\\\n",
      "        TimeLLM (Zero-shot) (GPT2) & 28.23 & 19.75 \\\\\n",
      "        Chronos (Zero-shot) (amazon-chronos-t5-tiny) & 29.90 & 19.77 \\\\\n",
      "        TimeLLM (Zero-shot) (BERT) & 28.45 & 19.84 \\\\\n",
      "        TimeLLM (Zero-shot) (LLAMA 7B (8 layers)) & 28.74 & 19.97 \\\\\n",
      "        TimeLLM (Zero-shot) (LLAMA 7B (16 layers)) & 29.45 & 20.31 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\label{tab:models_performance_comparison}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of models and their corresponding DataFrames\n",
    "from utils.result_saver import generate_model_comparison_from_dict\n",
    "\n",
    "\n",
    "model_dfs = {\n",
    "    # \"LSTM+WaveNet+GRU \\\\cite{DUDUKCU20211208}\": df1,\n",
    "    # \"Deep RL \\\\cite{DOMANSKI2024481}\": df2,\n",
    "    \"TimeLLM (Zero-shot)\": df_time_llm_inference,\n",
    "    \"TimeLLM (Fine-tuned)\": df_time_llm_training,\n",
    "    \"Chronos (Zero-shot)\": df_chronos_inference,\n",
    "    \"Chronos (Fine-tuned)\": df_chronos_training\n",
    "}\n",
    "\n",
    "# Generate model comparison table for seq=6, pred=9\n",
    "comparison_df, latex_code = generate_model_comparison_from_dict(model_dfs, seq=6, pred=9, save=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# import ace_tools as tools\n",
    "# tools.display_dataframe_to_user(name=\"Model Comparison Table\", dataframe=comparison_df)\n",
    "\n",
    "# Print LaTeX code (optional)\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\\\begin{table}[h]\\n    \\\\centering\\n    \\\\caption{Cross-Patient Model Performance}\\n    \\\\begin{tabular}{lcc|cc}\\n        \\\\toprule\\n        \\\\textbf{Model} & \\\\textbf{Train ID} & \\\\textbf{Test ID} & \\\\textbf{RMSE} & \\\\textbf{MAE} \\\\\\\\\\n        \\\\midrule\\n        GPT2 & 570 & 570 & 16.81 & 11.01 \\\\\\\\\\n         & 570 & 584 & 26.63 & 15.40 \\\\\\\\\\n         & 584 & 570 & 17.63 & 11.76 \\\\\\\\\\n         & 584 & 584 & 27.23 & 16.06 \\\\\\\\\\n        amazon-chronos-t5-base & 570 & 570 & 23.69 & 15.48 \\\\\\\\\\n         & 570 & 584 & 31.68 & 19.59 \\\\\\\\\\n         & 584 & 570 & 22.09 & 14.26 \\\\\\\\\\n         & 584 & 584 & 30.76 & 18.70 \\\\\\\\\\n        \\\\bottomrule\\n    \\\\end{tabular}\\n    \\\\label{tab:cross_patient_performance}\\n\\\\end{table}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.latex_tools import generate_cross_patient_latex_table_from_df\n",
    "\n",
    "cross_patient_df=pd.read_csv('../results/experiment_configs_crosspatient/experiment_results_crosspatient.csv')\n",
    "generate_cross_patient_latex_table_from_df(cross_patient_df,save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
