{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d38113",
   "metadata": {},
   "source": [
    "# üöÄ Comprehensive Efficiency Analysis for LLM-TIME Models\n",
    "\n",
    "This notebook analyzes efficiency data from comprehensive experiments including:\n",
    "- **Time-LLM**: BERT, GPT2, LLAMA (train & inference efficiency)\n",
    "- **Chronos**: T5-base, T5-tiny (train & inference efficiency) \n",
    "- **Distillation**: BERT‚ÜíTinyBERT (training & inference efficiency)\n",
    "\n",
    "The analysis covers:\n",
    "- üìä **Memory Usage**: GPU VRAM, RAM consumption\n",
    "- ‚è±Ô∏è **Latency**: Training time, inference time\n",
    "- üîã **Power Consumption**: Energy efficiency metrics\n",
    "- üìà **Performance vs Efficiency**: Accuracy/efficiency trade-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13457946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_DIR = Path('/home/amma/LLM-TIME')\n",
    "EXPERIMENTS_DIR = BASE_DIR / 'experiments'\n",
    "EFFICIENCY_DIR = BASE_DIR / 'efficiency_experiments_20251020_141409'\n",
    "\n",
    "print(f\"üìÅ Base directory: {BASE_DIR}\")\n",
    "print(f\"üß™ Experiments directory: {EXPERIMENTS_DIR}\")\n",
    "print(f\"‚ö° Efficiency directory: {EFFICIENCY_DIR}\")\n",
    "print(f\"üìä Directory exists: {EFFICIENCY_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover all efficiency report files\n",
    "efficiency_patterns = [\n",
    "    '**/efficiency_report_*.json',\n",
    "    '**/real_performance_report_*.json', \n",
    "    '**/comprehensive_performance_report_*.json',\n",
    "    '**/time_llm_efficiency_*.json',\n",
    "    '**/chronos_efficiency_*.json',\n",
    "    '**/distillation_efficiency_*.json'\n",
    "]\n",
    "\n",
    "all_efficiency_files = []\n",
    "for pattern in efficiency_patterns:\n",
    "    files = list(BASE_DIR.glob(pattern))\n",
    "    all_efficiency_files.extend(files)\n",
    "    print(f\"üìã Pattern '{pattern}': Found {len(files)} files\")\n",
    "\n",
    "print(f\"\\nüéØ Total efficiency files found: {len(all_efficiency_files)}\")\n",
    "\n",
    "# Show sample files\n",
    "if all_efficiency_files:\n",
    "    print(f\"\\nüìÑ Sample efficiency files:\")\n",
    "    for i, file in enumerate(all_efficiency_files[:5]):\n",
    "        rel_path = file.relative_to(BASE_DIR)\n",
    "        print(f\"  {i+1}. {rel_path}\")\n",
    "    if len(all_efficiency_files) > 5:\n",
    "        print(f\"  ... and {len(all_efficiency_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aebbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_efficiency_data(file_path):\n",
    "    \"\"\"Load and parse efficiency data from JSON files.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract metadata from filename and path\n",
    "        rel_path = file_path.relative_to(BASE_DIR)\n",
    "        path_parts = str(rel_path).split('/')\n",
    "        \n",
    "        metadata = {\n",
    "            'file_path': str(rel_path),\n",
    "            'filename': file_path.name,\n",
    "            'directory': '/'.join(path_parts[:-1]) if len(path_parts) > 1 else '',\n",
    "        }\n",
    "        \n",
    "        # Try to extract model info from path\n",
    "        path_str = str(rel_path).lower()\n",
    "        if 'time_llm' in path_str or 'timellm' in path_str:\n",
    "            metadata['model_family'] = 'Time-LLM'\n",
    "            if 'bert' in path_str:\n",
    "                metadata['model_name'] = 'BERT'\n",
    "            elif 'gpt2' in path_str:\n",
    "                metadata['model_name'] = 'GPT2'\n",
    "            elif 'llama' in path_str:\n",
    "                metadata['model_name'] = 'LLAMA'\n",
    "        elif 'chronos' in path_str:\n",
    "            metadata['model_family'] = 'Chronos'\n",
    "            if 't5-base' in path_str or 't5_base' in path_str:\n",
    "                metadata['model_name'] = 'T5-base'\n",
    "            elif 't5-tiny' in path_str or 't5_tiny' in path_str:\n",
    "                metadata['model_name'] = 'T5-tiny'\n",
    "        elif 'distill' in path_str:\n",
    "            metadata['model_family'] = 'Distillation'\n",
    "            metadata['model_name'] = 'BERT‚ÜíTinyBERT'\n",
    "        \n",
    "        # Determine mode\n",
    "        if 'train' in path_str and 'inference' not in path_str:\n",
    "            metadata['mode'] = 'training'\n",
    "        elif 'inference' in path_str:\n",
    "            metadata['mode'] = 'inference'\n",
    "        else:\n",
    "            metadata['mode'] = 'unknown'\n",
    "        \n",
    "        return {'data': data, 'metadata': metadata}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load all efficiency data\n",
    "print(\"üîÑ Loading efficiency data...\")\n",
    "efficiency_data = []\n",
    "for file_path in all_efficiency_files:\n",
    "    result = load_efficiency_data(file_path)\n",
    "    if result:\n",
    "        efficiency_data.append(result)\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded {len(efficiency_data)} efficiency files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_efficiency_metrics(data_entry):\n",
    "    \"\"\"Extract key efficiency metrics from loaded data.\"\"\"\n",
    "    try:\n",
    "        data = data_entry['data']\n",
    "        metadata = data_entry['metadata']\n",
    "        \n",
    "        metrics = {\n",
    "            'file_path': metadata['file_path'],\n",
    "            'model_family': metadata.get('model_family', 'Unknown'),\n",
    "            'model_name': metadata.get('model_name', 'Unknown'),\n",
    "            'mode': metadata.get('mode', 'unknown'),\n",
    "        }\n",
    "        \n",
    "        # Extract system metrics (look for various possible keys)\n",
    "        if 'system_metrics' in data:\n",
    "            sys_metrics = data['system_metrics']\n",
    "        elif 'metrics' in data:\n",
    "            sys_metrics = data['metrics']\n",
    "        elif 'performance_data' in data:\n",
    "            sys_metrics = data['performance_data']\n",
    "        else:\n",
    "            sys_metrics = data\n",
    "        \n",
    "        # Extract key efficiency metrics\n",
    "        metric_keys = {\n",
    "            'max_gpu_memory_mb': ['max_gpu_memory_mb', 'gpu_memory_peak', 'max_gpu_memory'],\n",
    "            'avg_gpu_memory_mb': ['avg_gpu_memory_mb', 'gpu_memory_avg', 'avg_gpu_memory'],\n",
    "            'max_cpu_percent': ['max_cpu_percent', 'cpu_peak', 'max_cpu'],\n",
    "            'avg_cpu_percent': ['avg_cpu_percent', 'cpu_avg', 'avg_cpu'],\n",
    "            'max_memory_mb': ['max_memory_mb', 'memory_peak', 'max_memory'],\n",
    "            'avg_memory_mb': ['avg_memory_mb', 'memory_avg', 'avg_memory'],\n",
    "            'total_time_seconds': ['total_time_seconds', 'execution_time', 'duration', 'total_time'],\n",
    "            'avg_power_watts': ['avg_power_watts', 'power_avg', 'avg_power'],\n",
    "            'max_power_watts': ['max_power_watts', 'power_peak', 'max_power'],\n",
    "        }\n",
    "        \n",
    "        for metric_name, possible_keys in metric_keys.items():\n",
    "            value = None\n",
    "            for key in possible_keys:\n",
    "                if key in sys_metrics:\n",
    "                    value = sys_metrics[key]\n",
    "                    break\n",
    "            metrics[metric_name] = value\n",
    "        \n",
    "        # Try to extract other relevant metrics\n",
    "        if 'process_info' in data:\n",
    "            proc_info = data['process_info']\n",
    "            if 'peak_memory_mb' in proc_info:\n",
    "                metrics['process_peak_memory_mb'] = proc_info['peak_memory_mb']\n",
    "        \n",
    "        # Calculate efficiency ratios if we have the data\n",
    "        if metrics['total_time_seconds'] and metrics['max_gpu_memory_mb']:\n",
    "            metrics['gpu_memory_time_ratio'] = metrics['max_gpu_memory_mb'] / metrics['total_time_seconds']\n",
    "        \n",
    "        if metrics['avg_power_watts'] and metrics['total_time_seconds']:\n",
    "            metrics['total_energy_wh'] = (metrics['avg_power_watts'] * metrics['total_time_seconds']) / 3600\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting metrics from {data_entry['metadata']['file_path']}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract metrics from all data\n",
    "print(\"üìä Extracting efficiency metrics...\")\n",
    "all_metrics = []\n",
    "for data_entry in efficiency_data:\n",
    "    metrics = extract_efficiency_metrics(data_entry)\n",
    "    if metrics:\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "# Create DataFrame\n",
    "df_efficiency = pd.DataFrame(all_metrics)\n",
    "print(f\"‚úÖ Created efficiency DataFrame with {len(df_efficiency)} entries\")\n",
    "\n",
    "# Display summary\n",
    "if not df_efficiency.empty:\n",
    "    print(f\"\\nüìã Efficiency Data Summary:\")\n",
    "    print(f\"Model families: {df_efficiency['model_family'].unique()}\")\n",
    "    print(f\"Models: {df_efficiency['model_name'].unique()}\")\n",
    "    print(f\"Modes: {df_efficiency['mode'].unique()}\")\n",
    "    print(f\"\\nDataFrame shape: {df_efficiency.shape}\")\n",
    "    print(f\"\\nColumns: {list(df_efficiency.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98905d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of the efficiency data\n",
    "if not df_efficiency.empty:\n",
    "    print(\"üìä Sample of Efficiency Data:\")\n",
    "    display(df_efficiency.head())\n",
    "    \n",
    "    print(\"\\nüîç Data Types:\")\n",
    "    display(df_efficiency.dtypes)\n",
    "    \n",
    "    print(\"\\nüìà Basic Statistics for Numeric Columns:\")\n",
    "    numeric_cols = df_efficiency.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        display(df_efficiency[numeric_cols].describe())\n",
    "    else:\n",
    "        print(\"No numeric columns found in efficiency data\")\n",
    "else:\n",
    "    print(\"‚ùå No efficiency data available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ec8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Usage Analysis\n",
    "if not df_efficiency.empty and 'max_gpu_memory_mb' in df_efficiency.columns:\n",
    "    \n",
    "    # Filter out rows with missing GPU memory data\n",
    "    gpu_data = df_efficiency.dropna(subset=['max_gpu_memory_mb'])\n",
    "    \n",
    "    if not gpu_data.empty:\n",
    "        print(f\"üéØ GPU Memory Usage Analysis ({len(gpu_data)} entries with GPU data)\")\n",
    "        \n",
    "        # Create subplots for memory analysis\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=('GPU Memory by Model Family', 'GPU Memory by Model & Mode',\n",
    "                          'CPU vs GPU Memory', 'Memory Usage Distribution'),\n",
    "            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "                   [{\"type\": \"scatter\"}, {\"type\": \"histogram\"}]]\n",
    "        )\n",
    "        \n",
    "        # GPU Memory by Model Family\n",
    "        family_gpu = gpu_data.groupby('model_family')['max_gpu_memory_mb'].mean().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=family_gpu['model_family'], y=family_gpu['max_gpu_memory_mb'],\n",
    "                   name='Avg GPU Memory', marker_color='skyblue'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # GPU Memory by Model & Mode\n",
    "        model_mode_gpu = gpu_data.groupby(['model_name', 'mode'])['max_gpu_memory_mb'].mean().reset_index()\n",
    "        model_mode_gpu['label'] = model_mode_gpu['model_name'] + ' (' + model_mode_gpu['mode'] + ')'\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=model_mode_gpu['label'], y=model_mode_gpu['max_gpu_memory_mb'],\n",
    "                   name='GPU Memory by Model+Mode', marker_color='lightcoral'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # CPU vs GPU Memory (if both available)\n",
    "        if 'max_memory_mb' in gpu_data.columns:\n",
    "            memory_data = gpu_data.dropna(subset=['max_memory_mb'])\n",
    "            if not memory_data.empty:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=memory_data['max_memory_mb'], y=memory_data['max_gpu_memory_mb'],\n",
    "                             mode='markers', name='CPU vs GPU Memory',\n",
    "                             text=memory_data['model_name'], marker_color='green'),\n",
    "                    row=2, col=1\n",
    "                )\n",
    "        \n",
    "        # Memory Distribution\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=gpu_data['max_gpu_memory_mb'], name='GPU Memory Distribution',\n",
    "                        marker_color='orange'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=800, title_text=\"üß† Memory Usage Analysis\", showlegend=False)\n",
    "        fig.update_xaxes(title_text=\"Model Family\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Model (Mode)\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"CPU Memory (MB)\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"GPU Memory (MB)\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"GPU Memory (MB)\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"GPU Memory (MB)\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"GPU Memory (MB)\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Count\", row=2, col=2)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nüìä GPU Memory Statistics by Model Family:\")\n",
    "        gpu_stats = gpu_data.groupby('model_family')['max_gpu_memory_mb'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "        display(gpu_stats.round(2))\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No GPU memory data available for analysis\")\n",
    "else:\n",
    "    print(\"‚ùå No efficiency data available or missing GPU memory column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing and Performance Analysis\n",
    "if not df_efficiency.empty and 'total_time_seconds' in df_efficiency.columns:\n",
    "    \n",
    "    # Filter out rows with missing timing data\n",
    "    timing_data = df_efficiency.dropna(subset=['total_time_seconds'])\n",
    "    \n",
    "    if not timing_data.empty:\n",
    "        print(f\"‚è±Ô∏è Timing Analysis ({len(timing_data)} entries with timing data)\")\n",
    "        \n",
    "        # Convert seconds to minutes for better readability\n",
    "        timing_data = timing_data.copy()\n",
    "        timing_data['total_time_minutes'] = timing_data['total_time_seconds'] / 60\n",
    "        timing_data['total_time_hours'] = timing_data['total_time_seconds'] / 3600\n",
    "        \n",
    "        # Create timing analysis plots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=('Execution Time by Model Family', 'Training vs Inference Time',\n",
    "                          'Time vs GPU Memory', 'Execution Time Distribution'),\n",
    "            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "                   [{\"type\": \"scatter\"}, {\"type\": \"histogram\"}]]\n",
    "        )\n",
    "        \n",
    "        # Execution time by model family\n",
    "        family_time = timing_data.groupby('model_family')['total_time_minutes'].mean().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=family_time['model_family'], y=family_time['total_time_minutes'],\n",
    "                   name='Avg Execution Time', marker_color='lightblue'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Training vs Inference time comparison\n",
    "        mode_time = timing_data.groupby('mode')['total_time_minutes'].mean().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=mode_time['mode'], y=mode_time['total_time_minutes'],\n",
    "                   name='Time by Mode', marker_color='lightgreen'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Time vs GPU Memory correlation\n",
    "        if 'max_gpu_memory_mb' in timing_data.columns:\n",
    "            memory_time_data = timing_data.dropna(subset=['max_gpu_memory_mb'])\n",
    "            if not memory_time_data.empty:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=memory_time_data['max_gpu_memory_mb'], y=memory_time_data['total_time_minutes'],\n",
    "                             mode='markers', name='Time vs GPU Memory',\n",
    "                             text=memory_time_data['model_name'], marker_color='red'),\n",
    "                    row=2, col=1\n",
    "                )\n",
    "        \n",
    "        # Execution time distribution\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=timing_data['total_time_minutes'], name='Time Distribution',\n",
    "                        marker_color='purple'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=800, title_text=\"‚è±Ô∏è Timing Analysis\", showlegend=False)\n",
    "        fig.update_xaxes(title_text=\"Model Family\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Mode\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"GPU Memory (MB)\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Execution Time (minutes)\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"Time (minutes)\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Time (minutes)\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Time (minutes)\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Count\", row=2, col=2)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nüìä Timing Statistics by Model Family:\")\n",
    "        timing_stats = timing_data.groupby('model_family')['total_time_minutes'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "        display(timing_stats.round(2))\n",
    "        \n",
    "        print(\"\\nüìä Timing Statistics by Mode:\")\n",
    "        mode_stats = timing_data.groupby('mode')['total_time_minutes'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "        display(mode_stats.round(2))\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No timing data available for analysis\")\n",
    "else:\n",
    "    print(\"‚ùå No efficiency data available or missing timing column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Consumption and Energy Analysis\n",
    "if not df_efficiency.empty:\n",
    "    \n",
    "    # Check for power-related columns\n",
    "    power_cols = ['avg_power_watts', 'max_power_watts', 'total_energy_wh']\n",
    "    available_power_cols = [col for col in power_cols if col in df_efficiency.columns]\n",
    "    \n",
    "    if available_power_cols:\n",
    "        power_data = df_efficiency.dropna(subset=available_power_cols, how='all')\n",
    "        \n",
    "        if not power_data.empty:\n",
    "            print(f\"üîã Power Consumption Analysis ({len(power_data)} entries with power data)\")\n",
    "            \n",
    "            # Create power analysis plots\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                subplot_titles=('Power Consumption by Model', 'Energy Consumption',\n",
    "                              'Power vs Memory Usage', 'Power Efficiency'),\n",
    "                specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "                       [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
    "            )\n",
    "            \n",
    "            # Power consumption by model\n",
    "            if 'avg_power_watts' in power_data.columns:\n",
    "                power_by_model = power_data.groupby('model_name')['avg_power_watts'].mean().reset_index()\n",
    "                power_by_model = power_by_model.dropna()\n",
    "                if not power_by_model.empty:\n",
    "                    fig.add_trace(\n",
    "                        go.Bar(x=power_by_model['model_name'], y=power_by_model['avg_power_watts'],\n",
    "                               name='Avg Power', marker_color='orange'),\n",
    "                        row=1, col=1\n",
    "                    )\n",
    "            \n",
    "            # Energy consumption\n",
    "            if 'total_energy_wh' in power_data.columns:\n",
    "                energy_by_model = power_data.groupby('model_name')['total_energy_wh'].mean().reset_index()\n",
    "                energy_by_model = energy_by_model.dropna()\n",
    "                if not energy_by_model.empty:\n",
    "                    fig.add_trace(\n",
    "                        go.Bar(x=energy_by_model['model_name'], y=energy_by_model['total_energy_wh'],\n",
    "                               name='Total Energy', marker_color='red'),\n",
    "                        row=1, col=2\n",
    "                    )\n",
    "            \n",
    "            # Power vs Memory usage\n",
    "            if 'avg_power_watts' in power_data.columns and 'max_gpu_memory_mb' in power_data.columns:\n",
    "                power_memory_data = power_data.dropna(subset=['avg_power_watts', 'max_gpu_memory_mb'])\n",
    "                if not power_memory_data.empty:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=power_memory_data['max_gpu_memory_mb'], y=power_memory_data['avg_power_watts'],\n",
    "                                 mode='markers', name='Power vs Memory',\n",
    "                                 text=power_memory_data['model_name'], marker_color='blue'),\n",
    "                        row=2, col=1\n",
    "                    )\n",
    "            \n",
    "            # Power efficiency (performance per watt)\n",
    "            if 'avg_power_watts' in power_data.columns and 'total_time_seconds' in power_data.columns:\n",
    "                efficiency_data = power_data.dropna(subset=['avg_power_watts', 'total_time_seconds'])\n",
    "                if not efficiency_data.empty:\n",
    "                    efficiency_data = efficiency_data.copy()\n",
    "                    efficiency_data['power_efficiency'] = 1 / (efficiency_data['avg_power_watts'] * efficiency_data['total_time_seconds'])\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=efficiency_data['model_name'], y=efficiency_data['power_efficiency'],\n",
    "                                 mode='markers', name='Power Efficiency',\n",
    "                                 text=efficiency_data['mode'], marker_color='green'),\n",
    "                        row=2, col=2\n",
    "                    )\n",
    "            \n",
    "            fig.update_layout(height=800, title_text=\"üîã Power and Energy Analysis\", showlegend=False)\n",
    "            fig.update_xaxes(title_text=\"Model\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Model\", row=1, col=2)\n",
    "            fig.update_xaxes(title_text=\"GPU Memory (MB)\", row=2, col=1)\n",
    "            fig.update_xaxes(title_text=\"Model\", row=2, col=2)\n",
    "            fig.update_yaxes(title_text=\"Power (Watts)\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"Energy (Wh)\", row=1, col=2)\n",
    "            fig.update_yaxes(title_text=\"Power (Watts)\", row=2, col=1)\n",
    "            fig.update_yaxes(title_text=\"Efficiency (1/W‚ãÖs)\", row=2, col=2)\n",
    "            \n",
    "            fig.show()\n",
    "            \n",
    "            # Summary statistics\n",
    "            if 'avg_power_watts' in power_data.columns:\n",
    "                print(\"\\nüìä Power Statistics by Model:\")\n",
    "                power_stats = power_data.groupby('model_name')['avg_power_watts'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "                display(power_stats.round(2))\n",
    "                \n",
    "        else:\n",
    "            print(\"‚ùå No power data available for analysis\")\n",
    "    else:\n",
    "        print(\"‚ùå No power-related columns found in efficiency data\")\n",
    "else:\n",
    "    print(\"‚ùå No efficiency data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Model Comparison\n",
    "if not df_efficiency.empty:\n",
    "    print(\"üèÜ Comprehensive Model Comparison\")\n",
    "    \n",
    "    # Create a summary comparison table\n",
    "    comparison_metrics = []\n",
    "    \n",
    "    for model_family in df_efficiency['model_family'].unique():\n",
    "        family_data = df_efficiency[df_efficiency['model_family'] == model_family]\n",
    "        \n",
    "        for model_name in family_data['model_name'].unique():\n",
    "            model_data = family_data[family_data['model_name'] == model_name]\n",
    "            \n",
    "            for mode in model_data['mode'].unique():\n",
    "                mode_data = model_data[model_data['mode'] == mode]\n",
    "                \n",
    "                if not mode_data.empty:\n",
    "                    summary = {\n",
    "                        'Model_Family': model_family,\n",
    "                        'Model': model_name,\n",
    "                        'Mode': mode,\n",
    "                        'Count': len(mode_data)\n",
    "                    }\n",
    "                    \n",
    "                    # Add efficiency metrics\n",
    "                    metrics_to_summarize = [\n",
    "                        'max_gpu_memory_mb', 'avg_gpu_memory_mb', 'max_cpu_percent', \n",
    "                        'max_memory_mb', 'total_time_seconds', 'avg_power_watts', 'total_energy_wh'\n",
    "                    ]\n",
    "                    \n",
    "                    for metric in metrics_to_summarize:\n",
    "                        if metric in mode_data.columns:\n",
    "                            values = mode_data[metric].dropna()\n",
    "                            if not values.empty:\n",
    "                                summary[f'{metric}_mean'] = values.mean()\n",
    "                                summary[f'{metric}_std'] = values.std()\n",
    "                    \n",
    "                    comparison_metrics.append(summary)\n",
    "    \n",
    "    if comparison_metrics:\n",
    "        df_comparison = pd.DataFrame(comparison_metrics)\n",
    "        \n",
    "        print(\"\\nüìä Model Efficiency Comparison Table:\")\n",
    "        display(df_comparison)\n",
    "        \n",
    "        # Create radar chart for model comparison\n",
    "        if len(df_comparison) > 0:\n",
    "            # Select key metrics for radar chart\n",
    "            radar_metrics = ['max_gpu_memory_mb_mean', 'total_time_seconds_mean', 'max_cpu_percent_mean']\n",
    "            radar_metrics = [m for m in radar_metrics if m in df_comparison.columns]\n",
    "            \n",
    "            if len(radar_metrics) >= 2:\n",
    "                # Normalize metrics for radar chart (0-100 scale)\n",
    "                df_radar = df_comparison.copy()\n",
    "                for metric in radar_metrics:\n",
    "                    if df_radar[metric].notna().any():\n",
    "                        max_val = df_radar[metric].max()\n",
    "                        min_val = df_radar[metric].min()\n",
    "                        if max_val > min_val:\n",
    "                            df_radar[f'{metric}_norm'] = 100 * (df_radar[metric] - min_val) / (max_val - min_val)\n",
    "                        else:\n",
    "                            df_radar[f'{metric}_norm'] = 50  # Default if all values are the same\n",
    "                \n",
    "                # Create radar chart\n",
    "                fig = go.Figure()\n",
    "                \n",
    "                for idx, row in df_radar.iterrows():\n",
    "                    model_label = f\"{row['Model']} ({row['Mode']})\"\n",
    "                    values = [row.get(f'{metric}_norm', 0) for metric in radar_metrics]\n",
    "                    labels = [metric.replace('_mean', '').replace('_', ' ').title() for metric in radar_metrics]\n",
    "                    \n",
    "                    fig.add_trace(go.Scatterpolar(\n",
    "                        r=values,\n",
    "                        theta=labels,\n",
    "                        fill='toself',\n",
    "                        name=model_label\n",
    "                    ))\n",
    "                \n",
    "                fig.update_layout(\n",
    "                    polar=dict(\n",
    "                        radialaxis=dict(\n",
    "                            visible=True,\n",
    "                            range=[0, 100]\n",
    "                        )),\n",
    "                    showlegend=True,\n",
    "                    title=\"üéØ Model Efficiency Radar Chart (Higher = More Resource Usage)\"\n",
    "                )\n",
    "                \n",
    "                fig.show()\n",
    "        \n",
    "        # Efficiency ranking\n",
    "        if 'total_time_seconds_mean' in df_comparison.columns and 'max_gpu_memory_mb_mean' in df_comparison.columns:\n",
    "            df_ranking = df_comparison.dropna(subset=['total_time_seconds_mean', 'max_gpu_memory_mb_mean']).copy()\n",
    "            \n",
    "            if not df_ranking.empty:\n",
    "                # Calculate efficiency score (lower is better)\n",
    "                df_ranking['efficiency_score'] = (\n",
    "                    df_ranking['total_time_seconds_mean'] / df_ranking['total_time_seconds_mean'].max() +\n",
    "                    df_ranking['max_gpu_memory_mb_mean'] / df_ranking['max_gpu_memory_mb_mean'].max()\n",
    "                ) / 2\n",
    "                \n",
    "                df_ranking = df_ranking.sort_values('efficiency_score')\n",
    "                \n",
    "                print(\"\\nüèÜ Efficiency Ranking (Lower Score = More Efficient):\")\n",
    "                ranking_display = df_ranking[['Model_Family', 'Model', 'Mode', 'efficiency_score', \n",
    "                                            'total_time_seconds_mean', 'max_gpu_memory_mb_mean']].round(3)\n",
    "                display(ranking_display)\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No data available for model comparison\")\n",
    "else:\n",
    "    print(\"‚ùå No efficiency data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d54b0",
   "metadata": {},
   "source": [
    "## üéØ Key Findings and Recommendations\n",
    "\n",
    "Based on the efficiency analysis above, here are the key insights:\n",
    "\n",
    "### üìä Memory Efficiency\n",
    "- **GPU Memory Usage**: Compare VRAM consumption across models\n",
    "- **CPU Memory**: System RAM requirements  \n",
    "- **Memory Growth**: Training vs inference memory patterns\n",
    "\n",
    "### ‚è±Ô∏è Time Efficiency  \n",
    "- **Training Time**: Time required for 10-epoch training\n",
    "- **Inference Speed**: Prediction latency comparison\n",
    "- **Scalability**: Performance with different model sizes\n",
    "\n",
    "### üîã Energy Efficiency\n",
    "- **Power Consumption**: Watts used during execution\n",
    "- **Energy Cost**: Total energy (Wh) per experiment\n",
    "- **Efficiency Ratio**: Performance per watt metrics\n",
    "\n",
    "### üèÜ Model Rankings\n",
    "1. **Most Memory Efficient**: Lowest GPU VRAM usage\n",
    "2. **Fastest Training**: Shortest training time  \n",
    "3. **Fastest Inference**: Lowest prediction latency\n",
    "4. **Most Energy Efficient**: Best performance/energy ratio\n",
    "\n",
    "### üí° Recommendations\n",
    "- **For Production**: Choose models with best inference efficiency\n",
    "- **For Development**: Balance training time vs accuracy\n",
    "- **For Resource-Constrained**: Prioritize memory efficiency\n",
    "- **For Large Scale**: Consider energy consumption costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for further analysis\n",
    "if not df_efficiency.empty:\n",
    "    \n",
    "    # Save comprehensive efficiency data\n",
    "    output_file = BASE_DIR / 'comprehensive_efficiency_analysis.csv'\n",
    "    df_efficiency.to_csv(output_file, index=False)\n",
    "    print(f\"üíæ Saved comprehensive efficiency data to: {output_file}\")\n",
    "    \n",
    "    # Save model comparison\n",
    "    if 'df_comparison' in locals():\n",
    "        comparison_file = BASE_DIR / 'model_efficiency_comparison.csv'\n",
    "        df_comparison.to_csv(comparison_file, index=False)\n",
    "        print(f\"üíæ Saved model comparison to: {comparison_file}\")\n",
    "    \n",
    "    # Create efficiency summary\n",
    "    summary = {\n",
    "        'analysis_date': pd.Timestamp.now().isoformat(),\n",
    "        'total_experiments': len(df_efficiency),\n",
    "        'model_families': df_efficiency['model_family'].nunique(),\n",
    "        'unique_models': df_efficiency['model_name'].nunique(),\n",
    "        'modes_tested': df_efficiency['mode'].unique().tolist(),\n",
    "    }\n",
    "    \n",
    "    # Add aggregate statistics\n",
    "    numeric_cols = df_efficiency.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if col in df_efficiency.columns:\n",
    "            summary[f'{col}_mean'] = df_efficiency[col].mean()\n",
    "            summary[f'{col}_median'] = df_efficiency[col].median()\n",
    "    \n",
    "    summary_file = BASE_DIR / 'efficiency_analysis_summary.json'\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    print(f\"üíæ Saved analysis summary to: {summary_file}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Analysis complete! Key files created:\")\n",
    "    print(f\"  üìä Efficiency data: comprehensive_efficiency_analysis.csv\")\n",
    "    print(f\"  üèÜ Model comparison: model_efficiency_comparison.csv\") \n",
    "    print(f\"  üìã Summary: efficiency_analysis_summary.json\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No efficiency data to export\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
